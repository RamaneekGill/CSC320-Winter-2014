 
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<META NAME="ROBOTS" CONTENT="NOARCHIVE">
<META NAME="googleBOT" CONTENT="NOARCHIVE">

<TITLE> CSC320 Project 1: The Prokudin-Gorskii photo collection</TITLE>

</head>

<BODY> 

<h1> CSC320 Project 1: The Prokudin-Gorskii Colour Photo Collection (Worth: 8%)</h1>


<img src="emir.jpg" alt="emir" align="right">
<p><a href = "http://en.wikipedia.org/wiki/Sergey_Prokudin-Gorsky">Sergei Prokudin-Gorskii</a> was a pioneer of colour photography. In the early 20-th century, he travelled across Russia and took thousands of striking colour pictures. His technique consisted of taking three black-and-white pictures of the scene simultaneously, with each picture taken through a blue, green, or red filter. In 1948, his glass-plate negatives were purchased by the Library of Congress and are available <a href ="http://www.loc.gov/pictures/collection/prok/">on the web</a>.</p>
				
<p>In this project, you will explore techniques to automatically combine the <b>inverted</b> blue, green, and red-filtered negatives into one colour photo. </p>

<h2>The Input</h2>
As input, you will take in an image that contains the three <b>inverted</b> negatives (top to bottom: blue, green, red). An example of an image that you should work on is <a href = "00757v.jpg">here</a>. The images could be of different sizes. The images you should work with are are available <a href = "images.zip">here</a> (<a href = "images.tar">old link with tiff images</a>, which don't work on some (most?) systems).

<h2>Part 0</h2>
Briefly describe the image data that you are working with for the report. (This can be just one or two sentences.) Include examples of the images.

<h2>Part 1</h2>
<p>Write code to extract the three black-and-white <b>inverted</b> negatives from the input image and to produce a colour image by combining the three colour channels. 

<p>The three <b>inverted</b> negatives can be aligned by matching the three black-and-white inverted negatives to each other to determine the optimal alignment. I suggest matching the green and the red inverted negatives to the blue inverted negative. The matching can be performed by varying the displacement of the negative that is being matched from -10 to 10 pixels along both the x and the y directions to find the best displacement. The matching metrics could be Normalized Cross-Correlation (NCC) and Sum of Squared Differences (SSD).

<p>Obtain the colour image for several examples by matching the inverted negatives using both NCC and SSD. In your report, indicate which seems to work better. Are there any artefacts in the output? What may explain the artefacts

<p>For Part 1, you may assume that the input image will be of size similar to that of <a href = "00757v.jpg">00757v.jpg</a>

<p><i>Hints</i>
<ul>
	<li>Some tuning needs to be done before the matching works well: for example, if you do not crop out the borders, the matching is less reliable.
	<li> <strike>The input images are <i>negatives</i>. If the brightness ranges from 0 to 255, then for a negative n, the actual channel is 255-n.</strike> UPDATE: The images are pre-inverted. There is no need to invert them again.
	<li><b>NEW</b>: the images won't display correctly if the maximum intensity is above 1 and the type is float. To convert an image i to uint8, go i.astype(uint8), which returns a converted image.
 	<li>To increase the efficiency of your code, avoid using loops! For example, you should always prefer

<blockquote>
c = np.dot(u, v)
</blockquote>
over
<blockquote>
s = 0<br>
for x, y in zip(u, v): s += x*y
</blockquote>
	<li>Suggestion for checking your code: take any colour photo, and try to align its three colour channels. The optimal displacement for channels of a single photo will very likely  be (0, 0) (though that's not guaranteed...).
</ul>

<h2>Part 2</h2>
The technique from Part 1 will only work for small images, and will take too long for larger images. This problem can be solved by rescaling the images with scipy.misc.imresize(), matching the small versions of the images to obtain a rough estimate of the match, and only then matching the large versions of the images. This procedure could be repeated several times. Implement matching so that it works for larger images as well. In the report, describe your results and the runtimes that you obtain.


<h2>What to submit</h2>
<p>The project should be done using Python 2 and should run on CDF. Your report should be in PDF format. You should use LaTeX to generate the report, and submit the .tex file as well. A sample template will be posted soon. 

<p><b>Important</b>:
<ul>
	<li>Readability counts! If your code isn't readable or your report doesn't make sense, they are not that useful. In addition, the TA can't read them. You will lose marks for those things. 
	<li>It is perfectly fine to discuss general ideas with other people, <i>if you acknowledge ideas in your report that are not your own</i>. However, you must not look at other people's code, or show your code to other people, and you must not look at other people's reports, or show your report to other people. All of those things are academic offenses.
</ul>

<H2>Marking Schemce</h2>

<p><a href = "marking_scheme.txt">Marking scheme</a></p>


<h2>Acknowledgements</h2>
The project was created by <a href = "http://www.eecs.berkeley.edu/~efros/">Alexei Efros</a>.


  <p>
    <a href="http://validator.w3.org/check?uri=referer"><img
        src="http://www.w3.org/Icons/valid-html401"
        alt="Valid HTML 4.01 Transitional" height="31" width="88"></a>
  </p>
  

</BODY></HTML>
